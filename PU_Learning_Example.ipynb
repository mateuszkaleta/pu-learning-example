{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PU Learning Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfF5OOwx2R+6CnGc7EgjI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateuszkaleta/pu-learning-example/blob/master/PU_Learning_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDTr8JQOKyYE",
        "colab_type": "text"
      },
      "source": [
        "# Przykład zastosowania metod PU Learning\n",
        "\n",
        "Ten notebook zawiera praktyczny przykład do artykułu zamieszczonego na blogu technicznym ING (**link**).\n",
        "\n",
        "## Dane\n",
        "\n",
        "Na potrzeby prezentacji, wykorzystany zostanie dataset Banknote Authentication, dostępny tu: http://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
        "\n",
        "Jest to zbiór danych o czterech atrybutach numerycznych, w zadaniu binarnej klasyfikacji. Zbiór ulegnie takiej modyfikacji, by odpowiadał warunkom PU learningu.\n",
        "\n",
        "Atrybuty to wariancja, kurtoza, skośność oraz entropia zdjęć banknotów, poddanych transformacji falkowej.\n",
        "\n",
        "## Algorytm\n",
        "\n",
        "Jak wspomniane jest w artykule, zastosowana będzie tu metoda dwukrokowa. W pierwszym kroku należy utworzyć zbiór *reliable negatives*, w drugim zbudować klasyfikator binarny.\n",
        "\n",
        "Jeżeli chodzi o implementację, to w pierwszym kroku dokonamy klasteryzacji zbioru. Zbiór zawierający najmniej znanych, pozytywnych instancji, posłuży jako zbiór negatywny w kroku budowy klasyfikatora binarnego. Taka metoda nazywa się C-CRNE (Clustering-based method for Collecting Reliable Negative Examples)\n",
        "\n",
        "W drugim etapie, zostanie zbudowany model SVC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx0iodQxJYVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scikit-learn==0.22.2 pandas==1.0.3 plotly==4.6.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_yA-zuaKDHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjrTB7D3RzmB",
        "colab_type": "text"
      },
      "source": [
        "## Jak wyglądają dane?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjv7WnUmKJ5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['variance', 'skewness', 'curtosis', 'entropy']\n",
        "columns = features + ['class']\n",
        "dataset_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
        "pu_dataset = pd.read_csv(dataset_url, names=columns)\n",
        "pu_dataset['class'] = pd.Categorical(pu_dataset['class'])\n",
        "pu_dataset.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuPiK6N0PyRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pu_dataset.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4jNMLcC9nJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(features)):\n",
        "  for j in range(i, len(features)):\n",
        "    if i != j:\n",
        "      fig = px.scatter(\n",
        "          pu_dataset, \n",
        "          x=features[i], y=features[j], \n",
        "          color='class', \n",
        "          marginal_y=\"violin\", \n",
        "          marginal_x=\"histogram\", \n",
        "          title=f'{features[i]} against {features[j]}',\n",
        "          color_discrete_sequence={1: 'rgba(20, 100, 180, 0.6)', 0: 'rgba(120, 100, 0, 0.6)'},\n",
        "          width=1280, height=720\n",
        "      )\n",
        "      fig.show()\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lAb-6hpSmy5",
        "colab_type": "text"
      },
      "source": [
        "Dla celów porównawczych, przed usunięciem etykiet, pozostawiam zbiór walidacyjny. Na taki komfort można sobie pozwolić oczywiście jedynie w prezentacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKJx5aL1S_eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# zapewnienie, że numpy będzie zwracać takie same liczby pseudolosowe\n",
        "np.random.seed(3655867)\n",
        "\n",
        "# losowe 20% instancji zostanie wybrane na zbiór walidacyjny\n",
        "validation_set_share = 20/100\n",
        "\n",
        "# na potrzeby prezentacji, wyrzucone zostanie 95% etykiet dla klasy pozytywnej i wszystkie dla klasy negatywnej\n",
        "label_frequency = 5/100\n",
        "\n",
        "all_indices = np.random.permutation(pu_dataset.index)\n",
        "split_point = int(validation_set_share * len(pu_dataset))\n",
        "training_indices = all_indices[split_point:]\n",
        "test_indices = all_indices[:split_point]\n",
        "\n",
        "class_distribution = pd.concat((pu_dataset.loc[training_indices]['class'], pu_dataset.loc[test_indices]['class']), axis=1).astype(float).describe().loc[['count', 'mean']]\n",
        "class_distribution.columns = ['Training set', 'Test set']\n",
        "class_distribution.index.name = 'Labels'\n",
        "class_distribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2bI9Xe5cm2n",
        "colab_type": "text"
      },
      "source": [
        "Mamy podobny rozkład klas w zbiorze testowym i treningowym, będziemy mogli zatem rzetelnie ocenić pracę klasyfikatora."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVgYEkT_WYLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# usunięcie etykiet instancji negatywnych i części etykiet instancji pozytywnych (zgodnie z wartością label_frequency)\n",
        "pu_dataset.loc[training_indices, 'selected'] = (np.random.uniform(low=0, high=1, size=len(training_indices)) < label_frequency).astype(int)\n",
        "pu_dataset.loc[training_indices, 'selected'] *= pu_dataset.loc[training_indices, 'class'].astype(int)\n",
        "pu_dataset['selected'] = pd.Categorical(pu_dataset['selected'])\n",
        "pu_dataset.loc[training_indices, ['class', 'selected']].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-YF34kuqvf3U",
        "colab": {}
      },
      "source": [
        "pu_dataset.loc[training_indices, 'class'] = None\n",
        "pu_dataset.loc[test_indices, 'selected'] = None\n",
        "pu_dataset.rename(columns={'selected': 'pu_label'}, inplace=True)\n",
        "(pu_dataset['pu_label'].value_counts() / len(training_indices)).round(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsojWH1UIsnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pu_dataset.loc[test_indices, 'class'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtcK-WJDIwOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pu_dataset.loc[training_indices, 'pu_label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJkhOkqiDnNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = px.scatter_matrix(\n",
        "    pu_dataset.loc[training_indices],\n",
        "    dimensions=features, \n",
        "    title='PU label distribution in training set',\n",
        "    labels=pu_dataset.loc[training_indices, 'pu_label'], \n",
        "    color=pu_dataset.loc[training_indices, 'pu_label'], \n",
        "    color_discrete_sequence={1: 'rgb(20, 100, 180)', 0: 'rgba(180, 180, 180, 0.2)'}\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "fig = px.scatter_matrix(\n",
        "    pu_dataset.loc[test_indices], \n",
        "    dimensions=features, \n",
        "    title='Clas distribution in test set',\n",
        "    labels=pu_dataset.loc[test_indices, 'class'], \n",
        "    color=pu_dataset.loc[test_indices, 'class'], \n",
        "    color_discrete_sequence={1: 'rgba(20, 100, 180, 0.6)', 0: 'rgba(120, 100, 0, 0.6)'}\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_odfn0lseGGJ",
        "colab_type": "text"
      },
      "source": [
        "**Powyżej widać, że rozkład zmiennej zależnej jest zupełnie inny, niż w ogólnej populacji (tam ok. 45% to pozytywne przypadki).** \n",
        "\n",
        "# Budowa modelu PU Learning\n",
        "\n",
        "Zastosowana zostanie metoda **C-CRNE** (*Clustering-based method for Collecting Reliable Negative Examples*) w połączeniu z **Iterative SVM**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnItge5ogt7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardyzacja danych\n",
        "pu_dataset[features] = (pu_dataset[features].mean() - pu_dataset[features]) / pu_dataset[features].std()\n",
        "\n",
        "assert ~(np.isin(test_indices, training_indices).any())\n",
        "training_dataset = pu_dataset.loc[training_indices].copy()\n",
        "test_dataset = pu_dataset.loc[test_indices].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJO162Tk-ALb",
        "colab_type": "text"
      },
      "source": [
        "Pierwszym krokiem C-CRNE jest dokonanie klasteryzacji danych. W tym przypadku wybrałem KMeans, za pomocą silhouette_score wybieram optymalną liczbę klastrów."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOmAJceWdBwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import itertools\n",
        "\n",
        "# optymalizujemy liczbę klastrów\n",
        "hyperparameters_space = {\n",
        "    'n_clusters': list(range(3, 7)),\n",
        "    'random_state': (23542, 31521, 9114, 4507)\n",
        "}\n",
        "\n",
        "best_clusterer = None\n",
        "best_score = -1  # minimalna wartość silhouette score\n",
        "best_parameters = None\n",
        "\n",
        "run = 1\n",
        "for parameters_set in list(itertools.product(*hyperparameters_space.values())):\n",
        "  params = dict(zip(hyperparameters_space.keys(), parameters_set))\n",
        "  # faktyczna klasteryzacja\n",
        "  clusterer = KMeans(**params, n_jobs=4)\n",
        "  cluster_labels = clusterer.fit_predict(training_dataset[features])\n",
        "  # ewaluacja\n",
        "  silhouette_mean = silhouette_score(training_dataset[features], cluster_labels)\n",
        "  print(f'Run #{run}. Silhouette score: {silhouette_mean}')\n",
        "  # wybierany jest najlepszy podział\n",
        "  if silhouette_mean >= best_score:\n",
        "    best_score = silhouette_mean\n",
        "    best_clusterer = clusterer\n",
        "    best_parameters = params\n",
        "  run += 1\n",
        "\n",
        "print(f'Best score: {best_score}. Best parameters: {str(best_parameters)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjfBBg-_-rzD",
        "colab_type": "text"
      },
      "source": [
        "Następnie, spośród obliczonych klastrów, wybieramy ten, który zawiera najmniejszy odsetek znanych nam instancji klasy pozytywnej. Robimy to w myśl założenia o gładkości, czyli szukamy takiej grupy obserwacji, które mają najmniej wspólnego ze znanymi pozytywnymi przypadkami."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W4ccnEXgJ3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset['cluster'] = best_clusterer.predict(training_dataset[features])\n",
        "positives_per_cluster = training_dataset.groupby('cluster')['pu_label']\n",
        "positives_per_cluster_counts = positives_per_cluster.value_counts()\n",
        "positives_per_cluster_share = (positives_per_cluster_counts / positives_per_cluster.count()).loc[:, 1].sort_values()\n",
        "positives_per_cluster_share"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAvzlwJ5Dqy4",
        "colab_type": "text"
      },
      "source": [
        "Upewniamy się jeszcze, że wybrany klaster nie jest zbyt mały. Mogłoby się zdarzyć, że byłaby to nawet pojedyncza obserwacja, a ponieważ zaraz będziemy trenowali klasyfikator binarny, chcemy mieć sensownych rozmiarów próbkę instancji nieokreślonej klasy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-BIPg2U_hK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_cluster = positives_per_cluster_share.iloc[:1]\n",
        "100 * positives_per_cluster_counts.loc[best_cluster.index] / len(training_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvYe4QeGD3E4",
        "colab_type": "text"
      },
      "source": [
        "Jak widać, mamy całkiem przyjemny rezultat - aż czwarta część zbioru treningowego znalazła się w klastrze reliable negatives. Pozostaje wytrenowanie klasyfikatora."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9CnDiMAD38L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reliable_negatives = training_dataset[training_dataset['cluster'] == best_cluster.index[0]].copy()\n",
        "reliable_negatives = reliable_negatives[reliable_negatives['pu_label'] != 1]\n",
        "positives = training_dataset[training_dataset['pu_label'] == 1]\n",
        "positives = positives.loc[positives.index.isin(training_indices)]\n",
        "len(reliable_negatives), len(positives), len(training_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCJfeXp9GKTp",
        "colab_type": "text"
      },
      "source": [
        "## Iterative SVM\n",
        "\n",
        "Według tej techniki, kolejnym krokiem jest wytrenowanie modelu SVM na zbiorze znanych pozytywów i klastrze reliable negatives. Nie bez przypadku w nazwie metody występuje \"iterative\".\n",
        "\n",
        "Po utworzeniu klasyfikatora w danej iteracji, dokonana zostanie predykcja na zbiorze nieoznaczonym (kilkaset obserwacji, które nie biorą udziału w treningu modelu). Te instancje, które model wskaże jako negatywne, poszerzą w kolejnej iteracji zbiór reliable negatives. Należy jeszcze zadać jakieś kryterium stopu, np. maksymalną ilość iteracji, czy brak zmian w rozkładzie predykcji.\n",
        "\n",
        "Dodam, że będę tu wykonywał walidację krzyżową, chociaż należy pamiętać, że nie odpowiada to w pełni sytuacji klasyfikacji binarnej. Wciąż bowiem operujemy na zbiorze pozytywów i klastra, który *podejrzewamy* o zawieranie w większości negatywów."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1so0YYQE_Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "# będziemy przechowywali najlepsze estymatory z kolejnych iteracji\n",
        "best_estimators = []\n",
        "\n",
        "# parametry do ewaluacji w każdej iteracji\n",
        "params_grid = {\n",
        "    'C': (.1, .3, .5, 1),\n",
        "    'kernel': ('poly', 'rbf', 'sigmoid'),\n",
        "    'degree': (3, 4),\n",
        "    'random_state': (235325, 3462469)\n",
        "}\n",
        "\n",
        "last_iteration_unlabeled_count = len(training_indices) - (len(positives) + len(reliable_negatives))\n",
        "max_iterations = 10\n",
        "\n",
        "def stop_criterion(iteration, amount_of_unlabeled_instances):\n",
        "  global last_iteration_unlabeled_count\n",
        "  if iteration == max_iterations:\n",
        "    print('Max iterations reached')\n",
        "    return True\n",
        "  if amount_of_unlabeled_instances == 0:\n",
        "    print('No unlabeled instsances are left')\n",
        "    return True\n",
        "  if amount_of_unlabeled_instances == last_iteration_unlabeled_count:\n",
        "    print('No new reliable negatives were found')\n",
        "    # jeżeli nie potrafimy już przesunąć granicy decyzyjnej, również kończymy\n",
        "    return True\n",
        "  last_iteration_unlabeled_count = amount_of_unlabeled_instances\n",
        "\n",
        "iteration = 1\n",
        "while True:\n",
        "  print(f'Iteration {iteration} started')\n",
        "  # 'balanced' spowoduje dopasowanie wag do częstości występowania etykiety\n",
        "  estimator = SVC(class_weight='balanced')\n",
        "  # przy użyciu stratified shuffle split, losowo wybrane podzbiory walidacji krzyżowej\n",
        "  # będą posiadały podobny rozkład zmiennej niezależnej\n",
        "  split = StratifiedShuffleSplit(n_splits=5, train_size=0.9, random_state=9999)\n",
        "  # wyszukiwanie hiperparametrów\n",
        "  grid_search = GridSearchCV(\n",
        "    estimator, params_grid, \n",
        "    scoring=make_scorer(f1_score), cv=split, n_jobs=-1, refit=True\n",
        "  )\n",
        "  iteration_X = pd.concat((reliable_negatives[features], positives[features]), axis=0)\n",
        "  iteration_y = pd.concat((reliable_negatives['pu_label'], positives['pu_label']), axis=0)\n",
        "\n",
        "  # szukanie najlepszego estymatora\n",
        "  print(f'Training on {len(iteration_y)} observations')\n",
        "  grid_search.fit(iteration_X, iteration_y)\n",
        "  best_estimators.append(grid_search.best_estimator_)\n",
        "\n",
        "  # teraz, należy zaklasfyfikować nieoznaczone obserwacje\n",
        "  labeled_instances_indices = np.concatenate((reliable_negatives.index, positives.index))\n",
        "  unlabeled = training_dataset.loc[~training_dataset.index.isin(labeled_instances_indices)]\n",
        "  prediction = grid_search.best_estimator_.predict(unlabeled[features]).round()\n",
        "\n",
        "  # rozszerzanie zbioru reliable negatives\n",
        "  indicated_as_negatives = unlabeled.loc[~prediction.astype(bool)]\n",
        "  indicated_as_positives = unlabeled.loc[prediction.astype(bool)]\n",
        "  reliable_negatives = pd.concat((reliable_negatives, indicated_as_negatives), axis=0)\n",
        "  # do oznaczenia w kolejnej rundzie wybierane są te obserwacje,\n",
        "  # które model z aktualnej iteracji wskazał jako pozytywne\n",
        "  unlabeled = indicated_as_positives\n",
        "  amount_of_unlabeled_instances = len(unlabeled)\n",
        "\n",
        "  assert len(reliable_negatives) + len(positives) + len(unlabeled) == len(training_indices)\n",
        "  print(f'Unlabeled instances left: {len(unlabeled)}')\n",
        "\n",
        "  if stop_criterion(iteration, amount_of_unlabeled_instances):\n",
        "    print(\"Stopping\")\n",
        "    break\n",
        "  iteration += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRdtgKw5aFNN",
        "colab_type": "text"
      },
      "source": [
        "# Klasyfikator zbudowany\n",
        "\n",
        "Z każdej iteracji zachowałem najlepszy estymator. Dlaczego?\n",
        "\n",
        "Otóż istnieją różne strategie wyboru ostatecznego modelu. Może to być estymator z najlpeszej rundy, albo ensemble kilku modeli.\n",
        "\n",
        "Sprawdzimy oba rozwiązania na odłożonym na samym początku zbiorze walidacyjnym. Przypominam, że w zawodowej rzeczywistości moglibyśmy nie posiadać takiej możliwości."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEy7aXsHQVxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "\n",
        "class VotingClassifier:\n",
        "  # niestety, implementacja w sklearn wymaga wykonania metody fit()\n",
        "  # my mamy już wytrenowane estymatory\n",
        "\n",
        "  def __init__(self, estimators):\n",
        "    self._estimators = estimators\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = np.array([clf.predict(X) for clf in self._estimators])\n",
        "    return np.mean(predictions, axis=0).reshape(-1, ).round()\n",
        "\n",
        "\n",
        "ensemble = VotingClassifier(best_estimators)\n",
        "models = {f'Iteration-{i}-model': model for i, model in enumerate(best_estimators)}\n",
        "models['Ensemble'] = ensemble\n",
        "\n",
        "for model_id, model in models.items():\n",
        "  print(f'Evaluating {model_id}')\n",
        "  predictions = model.predict(test_dataset[features])\n",
        "  # zbiór walidacyjny był mimo wszystko całkiem zrównoważony\n",
        "  accuracy_score = balanced_accuracy_score(\n",
        "      test_dataset['class'],\n",
        "      predictions\n",
        "  )\n",
        "  f1_score_ = f1_score(\n",
        "      test_dataset['class'],\n",
        "      predictions\n",
        "  )\n",
        "  models[model_id] = {'Model': model_id, 'Accuracy score': accuracy_score, 'F1 score': f1_score_}\n",
        "\n",
        "pd.DataFrame.from_dict(models.values()).sort_values(['F1 score', 'Accuracy score', 'Model'], ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrBNm0MSTeyy",
        "colab_type": "text"
      },
      "source": [
        "## Podsumowanie\n",
        "\n",
        "Udało się zbudować całkiem niezły model. To oczywiście nie stanowi gwarancji sukcesu w innych aplikacjach, niejednokrotnie spotkamy się z kiepskimi wynikami.Możemy natrafić na problemy z klasteryzacją, czy zbiór danych, w którym obserwacje obu klas są dość zbliżone do siebie co do rozkładu\n",
        "\n",
        "## Modyfikacje\n",
        "\n",
        "Dla chętnych, ciekawym rozwiązaniem jest algorytm GPU (:)) - Generative Positive-Unlabeled. W tym przypadku, zamiast klasteryzować istniejący zbiór danych, proponuje się stworzenie modelu generatywnego klasy pozytywnej. Chodzi o to, by model nauczył się rozkładu atrybutów obserwacji klasy pozytywnej.\n",
        "\n",
        "Jako zbiór reliable negatives przyjmuje się następnie te obserwacje nieposiadające etykiet, które mają najmniejsze prawdopodobieństwo bycia wygenerowanym przez model generatywny.\n",
        "\n",
        "Dziękuję!\n"
      ]
    }
  ]
}